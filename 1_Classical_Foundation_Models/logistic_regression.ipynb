{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9f9bdf",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "**Logistic Regression** is a simple and interpretable model used for **binary classification**.\n",
    "\n",
    "### Formula\n",
    "- Linear output:  \n",
    "  $$z = \\mathbf{w}^\\top \\mathbf{x} + b$$\n",
    "- Sigmoid activation:  \n",
    "  $$\\hat{y} = \\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "### Loss Function\n",
    "- **Binary Cross-Entropy (BCE)**:  \n",
    "  $$\\mathcal{L}(y, \\hat{y}) = -y \\log(\\hat{y}) - (1 - y) \\log(1 - \\hat{y}) $$\n",
    "\n",
    "### Characteristics\n",
    "- ✅ Fast and easy to implement  \n",
    "- ✅ Probabilistic output  \n",
    "- ❌ Limited to linear decision boundaries\n",
    "\n",
    "### Common Use Case\n",
    "- Email spam detection  \n",
    "- Medical diagnosis (e.g., diabetes prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2065, Accuracy: 0.9350\n",
      "Epoch 2, Loss: 0.1347, Accuracy: 0.9583\n",
      "Epoch 3, Loss: 0.1220, Accuracy: 0.9621\n",
      "Epoch 4, Loss: 0.1157, Accuracy: 0.9639\n",
      "Epoch 5, Loss: 0.1121, Accuracy: 0.9649\n",
      "Epoch 6, Loss: 0.1085, Accuracy: 0.9664\n",
      "Epoch 7, Loss: 0.1067, Accuracy: 0.9676\n",
      "Epoch 8, Loss: 0.1052, Accuracy: 0.9680\n",
      "Epoch 9, Loss: 0.1038, Accuracy: 0.9691\n",
      "Epoch 10, Loss: 0.1022, Accuracy: 0.9695\n",
      "Test Accuracy: 0.9550\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "def My_sigmoid(z):\n",
    "    return 1 / (1 + torch.exp(-z))\n",
    "\n",
    "def My_binary_cross_entropy(pred, target):\n",
    "    epsilon = 1e-7  # Avoid log(0)\n",
    "    pred = torch.clamp(pred, epsilon, 1 - epsilon)\n",
    "    return -(target * torch.log(pred) + (1 - target) * torch.log(1 - pred)).mean()  \n",
    "\n",
    "# ===== Logistic Regression Model =====\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return My_sigmoid(self.linear(x)) # or use torch.sigmoid(self.linear(x))\n",
    "\n",
    "# ===== Only keep 3 and 8 =====\n",
    "def filter_3_and_8(dataset):\n",
    "    idx = (dataset.targets == 3) | (dataset.targets == 8)\n",
    "    dataset.targets = dataset.targets[idx]\n",
    "    dataset.data = dataset.data[idx]\n",
    "    # 3 -> 0, 8 -> 1\n",
    "    dataset.targets = (dataset.targets == 8).long()\n",
    "    return dataset\n",
    "\n",
    "def main():\n",
    "    batch_size = 64\n",
    "    lr = 0.1\n",
    "    num_epochs = 10\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.view(-1))  # Flatten 784-dimensional vector, or use nn.Flatten()\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_dataset = filter_3_and_8(train_dataset)\n",
    "    test_dataset = filter_3_and_8(test_dataset)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1000)\n",
    "\n",
    "    model = LogisticRegression(784)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # ===== Training =====\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x, y in train_loader:\n",
    "            pred = model(x).squeeze(1)\n",
    "            criterion = nn.BCELoss()  # or use loss = My_binary_cross_entropy(pred, y.float())\n",
    "            loss = criterion(pred, y.float())  \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = (pred > 0.5).long()\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/total:.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # ===== Testing =====\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            pred = model(x).squeeze(1)\n",
    "            preds = (pred > 0.5).long()\n",
    "            acc = (preds == y).float().mean().item()\n",
    "            print(f\"Test Accuracy: {acc:.4f}\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Zero-to-Hero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
